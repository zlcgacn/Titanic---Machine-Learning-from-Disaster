{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88185aed",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-02-19T06:32:08.857028Z",
     "iopub.status.busy": "2025-02-19T06:32:08.856559Z",
     "iopub.status.idle": "2025-02-19T06:32:12.437970Z",
     "shell.execute_reply": "2025-02-19T06:32:12.436432Z"
    },
    "papermill": {
     "duration": 3.588822,
     "end_time": "2025-02-19T06:32:12.440241",
     "exception": false,
     "start_time": "2025-02-19T06:32:08.851419",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/titanic/train.csv\n",
      "/kaggle/input/titanic/test.csv\n",
      "/kaggle/input/titanic/gender_submission.csv\n",
      "/kaggle/input/titanics-data/train.csv\n",
      "/kaggle/input/titanics-data/test.csv\n",
      "/kaggle/input/titanics-data/gender_submission.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5065b33d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T06:32:12.448243Z",
     "iopub.status.busy": "2025-02-19T06:32:12.447623Z",
     "iopub.status.idle": "2025-02-19T06:32:12.475518Z",
     "shell.execute_reply": "2025-02-19T06:32:12.474125Z"
    },
    "papermill": {
     "duration": 0.034014,
     "end_time": "2025-02-19T06:32:12.477719",
     "exception": false,
     "start_time": "2025-02-19T06:32:12.443705",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "train_df = pd.read_csv('/kaggle/input/titanics-data/train.csv')\n",
    "test_df = pd.read_csv('/kaggle/input/titanics-data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da7bfcb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T06:32:12.485146Z",
     "iopub.status.busy": "2025-02-19T06:32:12.484762Z",
     "iopub.status.idle": "2025-02-19T06:32:12.526695Z",
     "shell.execute_reply": "2025-02-19T06:32:12.525153Z"
    },
    "papermill": {
     "duration": 0.04796,
     "end_time": "2025-02-19T06:32:12.528802",
     "exception": false,
     "start_time": "2025-02-19T06:32:12.480842",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 观察数据\n",
    "print(train_df.head())\n",
    "print(train_df.info())  # 查看数据类型和缺失值情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d73da821",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T06:32:12.536463Z",
     "iopub.status.busy": "2025-02-19T06:32:12.536022Z",
     "iopub.status.idle": "2025-02-19T06:32:12.559412Z",
     "shell.execute_reply": "2025-02-19T06:32:12.558247Z"
    },
    "papermill": {
     "duration": 0.029393,
     "end_time": "2025-02-19T06:32:12.561288",
     "exception": false,
     "start_time": "2025-02-19T06:32:12.531895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId    0\n",
      "Survived       0\n",
      "Pclass         0\n",
      "Name           0\n",
      "Sex            0\n",
      "Age            0\n",
      "SibSp          0\n",
      "Parch          0\n",
      "Ticket         0\n",
      "Fare           0\n",
      "Embarked       0\n",
      "dtype: int64\n",
      "PassengerId    0\n",
      "Pclass         0\n",
      "Name           0\n",
      "Sex            0\n",
      "Age            0\n",
      "SibSp          0\n",
      "Parch          0\n",
      "Ticket         0\n",
      "Fare           0\n",
      "Embarked       0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-4659dfa4a9bb>:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_df['Age'].fillna(train_df['Age'].median(), inplace=True)\n",
      "<ipython-input-4-4659dfa4a9bb>:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_df['Age'].fillna(test_df['Age'].median(), inplace=True)\n",
      "<ipython-input-4-4659dfa4a9bb>:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_df['Fare'].fillna(train_df['Fare'].median(), inplace=True)\n",
      "<ipython-input-4-4659dfa4a9bb>:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_df['Fare'].fillna(test_df['Fare'].median(), inplace=True)\n",
      "<ipython-input-4-4659dfa4a9bb>:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_df['Embarked'].fillna(train_df['Embarked'].mode()[0], inplace=True)\n",
      "<ipython-input-4-4659dfa4a9bb>:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_df['Embarked'].fillna(test_df['Embarked'].mode()[0], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#处理缺失值\n",
    "\n",
    "# 填充 Age 缺失值（用中位数填充）\n",
    "train_df['Age'].fillna(train_df['Age'].median(), inplace=True)\n",
    "test_df['Age'].fillna(test_df['Age'].median(), inplace=True)\n",
    "\n",
    "# 填充 Fare 缺失值（用中位数填充）\n",
    "train_df['Fare'].fillna(train_df['Fare'].median(), inplace=True)\n",
    "test_df['Fare'].fillna(test_df['Fare'].median(), inplace=True)\n",
    "\n",
    "# 填充 Embarked 缺失值（用众数填充）\n",
    "train_df['Embarked'].fillna(train_df['Embarked'].mode()[0], inplace=True)\n",
    "test_df['Embarked'].fillna(test_df['Embarked'].mode()[0], inplace=True)\n",
    "\n",
    "# 删除 Cabin 列（缺失值太多）\n",
    "train_df.drop(columns=['Cabin'], inplace=True)\n",
    "test_df.drop(columns=['Cabin'], inplace=True)\n",
    "\n",
    "# 确保没有缺失值\n",
    "print(train_df.isnull().sum())\n",
    "print(test_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aee57d2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T06:32:12.569109Z",
     "iopub.status.busy": "2025-02-19T06:32:12.568720Z",
     "iopub.status.idle": "2025-02-19T06:32:12.607669Z",
     "shell.execute_reply": "2025-02-19T06:32:12.606356Z"
    },
    "papermill": {
     "duration": 0.045485,
     "end_time": "2025-02-19T06:32:12.609990",
     "exception": false,
     "start_time": "2025-02-19T06:32:12.564505",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived        int64\n",
      "Pclass          int64\n",
      "Sex             int64\n",
      "Age           float64\n",
      "SibSp           int64\n",
      "Parch           int64\n",
      "Embarked_Q       bool\n",
      "Embarked_S       bool\n",
      "Title         float64\n",
      "FamilySize      int64\n",
      "Fare_log      float64\n",
      "dtype: object\n",
      "Pclass          int64\n",
      "Sex             int64\n",
      "Age           float64\n",
      "SibSp           int64\n",
      "Parch           int64\n",
      "Embarked_Q       bool\n",
      "Embarked_S       bool\n",
      "Title         float64\n",
      "FamilySize      int64\n",
      "Fare_log      float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#处理类别变量\n",
    "# 转换 Sex（male -> 0, female -> 1）\n",
    "train_df['Sex'] = train_df['Sex'].map({'male': 0, 'female': 1})\n",
    "test_df['Sex'] = test_df['Sex'].map({'male': 0, 'female': 1})\n",
    "\n",
    "# One-Hot 编码 Embarked\n",
    "train_df = pd.get_dummies(train_df, columns=['Embarked'], drop_first=True)\n",
    "test_df = pd.get_dummies(test_df, columns=['Embarked'], drop_first=True)\n",
    "\n",
    "#提取 Title（从 Name 中提取称谓）\n",
    "if 'Name' in train_df.columns:\n",
    "    train_df['Title'] = train_df['Name'].str.extract('([A-Za-z]+)\\.', expand=False)\n",
    "    test_df['Title'] = test_df['Name'].str.extract('([A-Za-z]+)\\.', expand=False)\n",
    "\n",
    "    title_mapping = {\n",
    "        'Mr': 1, 'Miss': 2, 'Mrs': 3, 'Master': 4, \n",
    "        'Dr': 5, 'Rev': 6, 'Col': 7, 'Major': 7, 'Mlle': 2, 'Mme': 3, \n",
    "        'Don': 8, 'Lady': 9, 'Countess': 9, 'Jonkheer': 8, 'Sir': 8, 'Capt': 7\n",
    "    }\n",
    "    train_df['Title'] = train_df['Title'].map(title_mapping).fillna(0)\n",
    "    test_df['Title'] = test_df['Title'].map(title_mapping).fillna(0)\n",
    "\n",
    "    # 删除 Name 列\n",
    "    train_df.drop(columns=['Name'], inplace=True)\n",
    "    test_df.drop(columns=['Name'], inplace=True)\n",
    "\n",
    "#创建家庭大小特征\n",
    "train_df['FamilySize'] = train_df['SibSp'] + train_df['Parch'] + 1\n",
    "test_df['FamilySize'] = test_df['SibSp'] + test_df['Parch'] + 1\n",
    "\n",
    "#票价取对数（处理异常值）\n",
    "train_df['Fare_log'] = np.log1p(train_df['Fare'])\n",
    "test_df['Fare_log'] = np.log1p(test_df['Fare'])\n",
    "\n",
    "#删除无关特征\n",
    "train_df.drop(columns=['Ticket', 'PassengerId', 'Fare'], inplace=True)\n",
    "test_df.drop(columns=['Ticket', 'PassengerId', 'Fare'], inplace=True)\n",
    "\n",
    "#确保所有数据都是数值类型\n",
    "print(train_df.dtypes)\n",
    "print(test_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "405a2da1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T06:32:12.620294Z",
     "iopub.status.busy": "2025-02-19T06:32:12.619885Z",
     "iopub.status.idle": "2025-02-19T06:32:12.629379Z",
     "shell.execute_reply": "2025-02-19T06:32:12.628067Z"
    },
    "papermill": {
     "duration": 0.016123,
     "end_time": "2025-02-19T06:32:12.631473",
     "exception": false,
     "start_time": "2025-02-19T06:32:12.615350",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 目标变量\n",
    "y = train_df['Survived']\n",
    "X = train_df.drop(columns=['Survived'])  # 特征集\n",
    "\n",
    "# 划分训练集和验证集\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49e7b039",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T06:32:12.639979Z",
     "iopub.status.busy": "2025-02-19T06:32:12.639580Z",
     "iopub.status.idle": "2025-02-19T06:32:12.865112Z",
     "shell.execute_reply": "2025-02-19T06:32:12.863744Z"
    },
    "papermill": {
     "duration": 0.231947,
     "end_time": "2025-02-19T06:32:12.867056",
     "exception": false,
     "start_time": "2025-02-19T06:32:12.635109",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型准确率: 0.8268\n"
     ]
    }
   ],
   "source": [
    "# 训练随机森林模型\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 预测\n",
    "y_pred = model.predict(X_valid)\n",
    "\n",
    "# 计算准确率\n",
    "accuracy = accuracy_score(y_valid, y_pred)\n",
    "print(f'模型准确率: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "385aa984",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T06:32:12.875596Z",
     "iopub.status.busy": "2025-02-19T06:32:12.875201Z",
     "iopub.status.idle": "2025-02-19T06:32:12.907811Z",
     "shell.execute_reply": "2025-02-19T06:32:12.906378Z"
    },
    "papermill": {
     "duration": 0.039043,
     "end_time": "2025-02-19T06:32:12.909834",
     "exception": false,
     "start_time": "2025-02-19T06:32:12.870791",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测结果已保存为 submission.csv\n"
     ]
    }
   ],
   "source": [
    "# 在测试集上进行预测\n",
    "test_predictions = model.predict(test_df)\n",
    "\n",
    "# 读取原始测试集，获取 PassengerId\n",
    "test_original = pd.read_csv('/kaggle/input/titanics-data/test.csv')\n",
    "\n",
    "# 生成提交文件\n",
    "submission = pd.DataFrame({'PassengerId': test_original['PassengerId'], 'Survived': test_predictions})\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"预测结果已保存为 submission.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 26502,
     "sourceId": 3136,
     "sourceType": "competition"
    },
    {
     "datasetId": 6646498,
     "sourceId": 10722026,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30886,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7.709547,
   "end_time": "2025-02-19T06:32:13.634928",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-19T06:32:05.925381",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
